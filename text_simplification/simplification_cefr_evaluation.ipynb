{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454ebb4e-b94e-4818-ab07-335a2c4212a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/tmp/ipykernel_3342/922525362.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAutoModelForSeq2SeqLM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9eed7f-52c8-4403-a033-c7d9282c96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e510e7-a785-4bab-925b-8767bc78ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 4\n",
      "INFO: Pandarallel will run on 3 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2ab32-e883-4c98-bc7c-adca86fbc729",
   "metadata": {},
   "source": [
    "## Define checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa55d818-bd77-4016-8b36-33e025c72fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './cache_mod'\n",
    "checkpoint_t5 = \"google/flan-t5-large\"\n",
    "checkpoint_dolly = \"databricks/dolly-v2-2-8b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033b5fc2-5a66-46ab-ae34-90b68be4600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, prompt, is_pipeline=False, max_new_tokens=100):\n",
    "    if is_pipeline:\n",
    "        return model(prompt)[0]['generated_text']\n",
    "    else:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ccd6-fdb9-4cbc-b934-e74b408a959b",
   "metadata": {},
   "source": [
    "## Read sample data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b5b8ca-7666-406a-855d-cc33e68deb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og.1</th>\n",
       "      <th>target_level_og.1</th>\n",
       "      <th>data_source.1</th>\n",
       "      <th>data_type</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1587</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1749</td>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000001750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data_source  source_level_og  target_level_og  Unnamed: 3  \\\n",
       "0  BreakingNewsEnglish              2.0              1.0        1587   \n",
       "1  BreakingNewsEnglish              2.0              1.0        1749   \n",
       "\n",
       "                                              source  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "\n",
       "                                              target  source_level_og.1  \\\n",
       "0  Donald Trump is interested in buying Greenland...                2.0   \n",
       "1  Everyone knows children don't like eating gree...                2.0   \n",
       "\n",
       "   target_level_og.1        data_source.1            data_type  \\\n",
       "0                1.0  BreakingNewsEnglish  text_simplification   \n",
       "1                1.0  BreakingNewsEnglish  text_simplification   \n",
       "\n",
       "   source_level_cefr  target_level_cefr           id  \n",
       "0                NaN                NaN  TS000001588  \n",
       "1                NaN                NaN  TS000001750  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Text_Simplification/trial_smpl_medium.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69792c96-1627-44b8-95f8-de188dfa8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55624d-0191-4e11-ae9e-007d83592c29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run simplification for various prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a1845-9b7f-4bff-ac7d-4ab2c2849c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer is loaded for Dolly\n",
      "Model is loaded for Dolly\n",
      "Running dolly...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prompts = [\"Simplify\",\"Simplify to elementary level\",\"Simplify to CEFR A1\",\"Simplify to intermediate level\", \"Simplify to CEFR B1\"]\n",
    "\n",
    "model_checkpoints = {\n",
    "    'dolly': checkpoint_dolly,\n",
    "    'flant5': checkpoint_t5\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, checkpoint in model_checkpoints.items():\n",
    "    if checkpoint == checkpoint_dolly:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        print(\"Tokenizer is loaded for Dolly\")\n",
    "        model = pipeline(model=checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n",
    "        print(\"Model is loaded for Dolly\")\n",
    "        is_pipeline = True\n",
    "        print(\"Running dolly...\")\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        print(\"Tokenizer is loaded for T5\")\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, cache_dir=cache_dir, device_map=\"auto\")\n",
    "        print(\"Model is loaded for T5\")\n",
    "        is_pipeline = False\n",
    "        print(\"Running t5...\")\n",
    "\n",
    "    for inst in prompts:\n",
    "        df[f\"{model_name}-{inst}\"] = df['source'].apply(lambda x: generate_text(model, tokenizer, inst + ': ' + x, is_pipeline=is_pipeline))\n",
    "        \n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d7caf-a259-491f-a323-20d2c36685c5",
   "metadata": {},
   "source": [
    "### Run the model in parallelized workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8444097-f1a2-4885-9f69-df6d1575b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.worker import worker\n",
    "import torch.multiprocessing as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73489627-4cbb-4876-8586-1f537f83b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ed2a4c-2d63-4f1b-b9ce-a210526bc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Model is loaded for dolly on device 0\n",
      "Model is loaded for dolly on device 0\n",
      "Model is loaded for dolly on device 0\n",
      "Model is loaded for dolly on device 0\n",
      "Model is loaded for flant5 on device 1\n",
      "Model is loaded for flant5 on device 1\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Model is loaded for flant5 on device 1\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Model is loaded for flant5 on device 1\n",
      "Model is loaded for dolly on device 0Model is loaded for flant5 on device 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>processes.append(p)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> p <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> processes:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>p.join()                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">process.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">join</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_closed()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._parent_pid == os.getpid(), <span style=\"color: #808000; text-decoration-color: #808000\">'can only join a child process'</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._popen <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'can only join a started process'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>res = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._popen.wait(timeout)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> res <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>_children.discard(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">popen_fork.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">48</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wait</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> wait([<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sentinel], timeout):                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># This shouldn't block if wait() returned successfully.</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>48 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.poll(os.WNOHANG <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> timeout == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.returncode                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_send_signal</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, sig):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">popen_fork.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">28</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">poll</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">poll</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, flag=os.WNOHANG):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.returncode <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>28 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pid, sts = os.waitpid(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pid, flag)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Child process not yet created. See #1731717</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># e.errno == errno.ECHILD == 10</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n",
       "\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m:\u001B[94m42\u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m39 \u001B[0m\u001B[2m│   │   \u001B[0mprocesses.append(p)                                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m40 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m41 \u001B[0m\u001B[94mfor\u001B[0m p \u001B[95min\u001B[0m processes:                                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m42 \u001B[2m│   \u001B[0mp.join()                                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m43 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/opt/conda/lib/python3.7/multiprocessing/\u001B[0m\u001B[1;33mprocess.py\u001B[0m:\u001B[94m140\u001B[0m in \u001B[92mjoin\u001B[0m                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m137 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m._check_closed()                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m138 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94massert\u001B[0m \u001B[96mself\u001B[0m._parent_pid == os.getpid(), \u001B[33m'\u001B[0m\u001B[33mcan only join a child process\u001B[0m\u001B[33m'\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m139 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94massert\u001B[0m \u001B[96mself\u001B[0m._popen \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m, \u001B[33m'\u001B[0m\u001B[33mcan only join a started process\u001B[0m\u001B[33m'\u001B[0m                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m140 \u001B[2m│   │   \u001B[0mres = \u001B[96mself\u001B[0m._popen.wait(timeout)                                                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m141 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m res \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m142 \u001B[0m\u001B[2m│   │   │   \u001B[0m_children.discard(\u001B[96mself\u001B[0m)                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m143 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/opt/conda/lib/python3.7/multiprocessing/\u001B[0m\u001B[1;33mpopen_fork.py\u001B[0m:\u001B[94m48\u001B[0m in \u001B[92mwait\u001B[0m                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m45 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m wait([\u001B[96mself\u001B[0m.sentinel], timeout):                                      \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m46 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[94mNone\u001B[0m                                                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m47 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# This shouldn't block if wait() returned successfully.\u001B[0m                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m48 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.poll(os.WNOHANG \u001B[94mif\u001B[0m timeout == \u001B[94m0.0\u001B[0m \u001B[94melse\u001B[0m \u001B[94m0\u001B[0m)                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m49 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.returncode                                                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m50 \u001B[0m\u001B[2m│   \u001B[0m                                                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m51 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_send_signal\u001B[0m(\u001B[96mself\u001B[0m, sig):                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/opt/conda/lib/python3.7/multiprocessing/\u001B[0m\u001B[1;33mpopen_fork.py\u001B[0m:\u001B[94m28\u001B[0m in \u001B[92mpoll\u001B[0m                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m25 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mpoll\u001B[0m(\u001B[96mself\u001B[0m, flag=os.WNOHANG):                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m26 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m.returncode \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m27 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m28 \u001B[2m│   │   │   │   \u001B[0mpid, sts = os.waitpid(\u001B[96mself\u001B[0m.pid, flag)                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m29 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mexcept\u001B[0m \u001B[96mOSError\u001B[0m \u001B[94mas\u001B[0m e:                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m30 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# Child process not yet created. See #1731717\u001B[0m                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m31 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# e.errno == errno.ECHILD == 10\u001B[0m                                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mKeyboardInterrupt\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helper.worker import worker\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# mp.set_start_method('spawn')\n",
    "\n",
    "device_ids = [0, 1]  # GPU IDs\n",
    "prompts = [\"Simplify\",\"Simplify to elementary level\",\"Simplify to CEFR A1\",\"Simplify to intermediate level\", \"Simplify to CEFR B1\"]\n",
    "\n",
    "model_checkpoints = {\n",
    "    'dolly': 'databricks/dolly-v2-2-8b',\n",
    "    'flant5': 'google/flan-t5-large'\n",
    "}\n",
    "\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "\n",
    "for model_name, checkpoint in model_checkpoints.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    if model_name == 'dolly':\n",
    "        model = pipeline(model=checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "    else:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, cache_dir='./cache_mod')\n",
    "    models[model_name] = model\n",
    "    tokenizers[model_name] = tokenizer\n",
    "\n",
    "processes = []\n",
    "for i, (model_name, checkpoint) in enumerate(model_checkpoints.items()):\n",
    "    device = device_ids[i % len(device_ids)]\n",
    "    for inst in prompts:\n",
    "        p = mp.Process(target=worker, args=(device, models[model_name], \n",
    "                                            tokenizers[model_name], \n",
    "                                            inst, \n",
    "                                            df, \n",
    "                                            model_name, \n",
    "                                            True if model_name=='dolly' else False))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b534f0-0f6b-4a01-b851-1992bad8ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Text_Simplification/simplified_df_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5b778-1960-4d31-8a3d-9442caf86fcc",
   "metadata": {},
   "source": [
    "## Add CEFR labels and evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532b6fbd-c034-4047-9f28-d77e097ee48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 4\n",
      "INFO: Pandarallel will run on 3 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d157e9-eee5-4722-b060-80a96cde9e11",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b758e0-83cd-4e37-a949-55ea23697406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>data_source</th>\n",
       "      <th>id</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>flant5-Simplify</th>\n",
       "      <th>flant5-Simplify to elementary level</th>\n",
       "      <th>flant5-Simplify to CEFR A1</th>\n",
       "      <th>flant5-Simplify to intermediate level</th>\n",
       "      <th>flant5-Simplify to CEFR B1</th>\n",
       "      <th>dolly-Simplify</th>\n",
       "      <th>dolly-Simplify to elementary level</th>\n",
       "      <th>dolly-Simplify to CEFR A1</th>\n",
       "      <th>dolly-Simplify to intermediate level</th>\n",
       "      <th>dolly-Simplify to CEFR B1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>TS000001588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump has said he would be interested i...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland.</td>\n",
       "      <td>Donald Trump is interested in buying Greenland.</td>\n",
       "      <td>Donald Trump is interested in buying Greenland.</td>\n",
       "      <td>Donald Trump is interested in buying Greenland.</td>\n",
       "      <td>Buy Greenland: Mr Trump said he was interested...</td>\n",
       "      <td>This is simplified to elementary level as all ...</td>\n",
       "      <td>Denmark does not own Greenland, although it ha...</td>\n",
       "      <td>Denmark owns Greenland. The future President o...</td>\n",
       "      <td>CEFR B1: Donald Trump is interested in buying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>TS000001750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Children dislike greens.</td>\n",
       "      <td>Children don't like eating greens. Parents can...</td>\n",
       "      <td>CEFR A1: Everyone knows that children don't li...</td>\n",
       "      <td>The study looked at the eating habits of young...</td>\n",
       "      <td>CEFR B1:</td>\n",
       "      <td>No wonder children don't like vegetables. Gene...</td>\n",
       "      <td>In short, children will not eat greens because...</td>\n",
       "      <td>CEFR A1: Everyone knows that children do not l...</td>\n",
       "      <td>Children do not like eating greens because the...</td>\n",
       "      <td>Children's' dislike of greens might be gene re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "\n",
       "                                              target  source_level_og  \\\n",
       "0  Donald Trump is interested in buying Greenland...              2.0   \n",
       "1  Everyone knows children don't like eating gree...              2.0   \n",
       "\n",
       "   target_level_og          data_source           id  source_level_cefr  \\\n",
       "0              1.0  BreakingNewsEnglish  TS000001588                NaN   \n",
       "1              1.0  BreakingNewsEnglish  TS000001750                NaN   \n",
       "\n",
       "   target_level_cefr                                    flant5-Simplify  \\\n",
       "0                NaN  Donald Trump has said he would be interested i...   \n",
       "1                NaN                           Children dislike greens.   \n",
       "\n",
       "                 flant5-Simplify to elementary level  \\\n",
       "0    Donald Trump is interested in buying Greenland.   \n",
       "1  Children don't like eating greens. Parents can...   \n",
       "\n",
       "                          flant5-Simplify to CEFR A1  \\\n",
       "0    Donald Trump is interested in buying Greenland.   \n",
       "1  CEFR A1: Everyone knows that children don't li...   \n",
       "\n",
       "               flant5-Simplify to intermediate level  \\\n",
       "0    Donald Trump is interested in buying Greenland.   \n",
       "1  The study looked at the eating habits of young...   \n",
       "\n",
       "                        flant5-Simplify to CEFR B1  \\\n",
       "0  Donald Trump is interested in buying Greenland.   \n",
       "1                                         CEFR B1:   \n",
       "\n",
       "                                      dolly-Simplify  \\\n",
       "0  Buy Greenland: Mr Trump said he was interested...   \n",
       "1  No wonder children don't like vegetables. Gene...   \n",
       "\n",
       "                  dolly-Simplify to elementary level  \\\n",
       "0  This is simplified to elementary level as all ...   \n",
       "1  In short, children will not eat greens because...   \n",
       "\n",
       "                           dolly-Simplify to CEFR A1  \\\n",
       "0  Denmark does not own Greenland, although it ha...   \n",
       "1  CEFR A1: Everyone knows that children do not l...   \n",
       "\n",
       "                dolly-Simplify to intermediate level  \\\n",
       "0  Denmark owns Greenland. The future President o...   \n",
       "1  Children do not like eating greens because the...   \n",
       "\n",
       "                           dolly-Simplify to CEFR B1  \n",
       "0  CEFR B1: Donald Trump is interested in buying ...  \n",
       "1  Children's' dislike of greens might be gene re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gs://XXX/Text_Simplification/simplified_df_new.csv\")\n",
    "\n",
    "## Make sure all the correct cols are selected below. Ow the pivot logic will fail\n",
    "df = df[[\"source\",\"target\",\"source_level_og\",\"target_level_og\",\"data_source\",\"id\",\"source_level_cefr\",\"target_level_cefr\",\"flant5-Simplify\",\"flant5-Simplify to elementary level\",\"flant5-Simplify to CEFR A1\",\"flant5-Simplify to intermediate level\",\"flant5-Simplify to CEFR B1\",\"dolly-Simplify\",\"dolly-Simplify to elementary level\",\"dolly-Simplify to CEFR A1\",\"dolly-Simplify to intermediate level\",\"dolly-Simplify to CEFR B1\"]]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d3ee1e-0f71-4bf3-86bf-81b5dfc5b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>data_source</th>\n",
       "      <th>id</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>TS000001588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flant5</td>\n",
       "      <td>Simplify</td>\n",
       "      <td>Donald Trump has said he would be interested i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>TS000001750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flant5</td>\n",
       "      <td>Simplify</td>\n",
       "      <td>Children dislike greens.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "\n",
       "                                              target  source_level_og  \\\n",
       "0  Donald Trump is interested in buying Greenland...              2.0   \n",
       "1  Everyone knows children don't like eating gree...              2.0   \n",
       "\n",
       "   target_level_og          data_source           id  source_level_cefr  \\\n",
       "0              1.0  BreakingNewsEnglish  TS000001588                NaN   \n",
       "1              1.0  BreakingNewsEnglish  TS000001750                NaN   \n",
       "\n",
       "   target_level_cefr   model    prompt  \\\n",
       "0                NaN  flant5  Simplify   \n",
       "1                NaN  flant5  Simplify   \n",
       "\n",
       "                                      generated_text  \n",
       "0  Donald Trump has said he would be interested i...  \n",
       "1                           Children dislike greens.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df.melt(id_vars=[\"source\",\"target\",\"source_level_og\",\"target_level_og\",\"data_source\",\"id\",\"source_level_cefr\",\"target_level_cefr\"], var_name=\"model_prompt\", value_name=\"generated_text\")\n",
    "df_long[['model', 'prompt']] = df_long['model_prompt'].str.split('-', expand=True)\n",
    "df_long = df_long[[\"source\",\"target\",\"source_level_og\",\"target_level_og\",\"data_source\",\"id\",\"source_level_cefr\",\"target_level_cefr\", \"model\",\"prompt\",\"generated_text\"]]\n",
    "\n",
    "df_long.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb74221-3b61-4d4a-93c2-6530a093eae1",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c75d9ae-74fe-4447-b456-f74ba7f266c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Note: low-income -> low income\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace special characters with whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Tokenize text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords from the text\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the words using WordNetLemmatizer\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Perform snowball stemming on the words\n",
    "    # stemmer = SnowballStemmer(\"english\")\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the preprocessed words back into a single string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    preprocessed_text = preprocessed_text.strip()\n",
    "    \n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb5e7c7-9a3b-4e2f-bc80-9bd26e9706c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[\"generated_text\"] = df_long[\"generated_text\"].parallel_apply(lambda t: preprocess_text(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e2e8b-bb3a-45b5-ba23-ba0d758cc4bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f296ec5-fd40-41c0-88a7-670edbae0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"XXX\"\n",
    "\n",
    "MODEL_BLOB_NAME = \"CEFR/models/cefr_ktrain_bert/tf_model.h5\"\n",
    "MODEL_FILE_NAME = \"./model/tf_model.h5\"\n",
    "\n",
    "PREPROC_BLOB_NAME = \"CEFR/models/cefr_ktrain_bert/tf_model.preproc\"\n",
    "PREPROC_FILE_NAME = \"./model/tf_model.preproc\"\n",
    "\n",
    "model_load_path = \"gs://XXX/CEFR/models/cefr_ktrain_bert/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897a7a05-f25a-4035-8628-6944fe07d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from COS bucket.\"\"\"\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd4d1b3-46f3-4961-b4a2-0ed1ae82eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 230388\n",
      "drwxr-xr-x 5 jupyter jupyter      4096 May 25 05:38 \u001B[0m\u001B[01;34m.\u001B[0m/\n",
      "drwxr-xr-x 6 jupyter jupyter      4096 May 17 20:14 \u001B[01;34m..\u001B[0m/\n",
      "drwxr-xr-x 2 jupyter jupyter      4096 May 24 17:36 \u001B[01;34m.ipynb_checkpoints\u001B[0m/\n",
      "drwxr-xr-x 2 jupyter jupyter      4096 May 17 20:53 \u001B[01;34m__pycache__\u001B[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter     12225 May 17 20:48 data_prep.py\n",
      "-rw-r--r-- 1 jupyter jupyter  16126579 May 18 14:56 huggingface_cefr_labeled.csv\n",
      "drwxr-xr-x 2 jupyter jupyter      4096 May 17 21:07 \u001B[01;34mmodel\u001B[0m/\n",
      "-rw-r--r-- 1 jupyter jupyter    183859 May 24 17:52 predict_cefr_label.ipynb\n",
      "-rw-r--r-- 1 jupyter jupyter     85481 May 25 05:38 simp_multmod.ipynb\n",
      "-rw-r--r-- 1 jupyter jupyter   5942659 May 25 05:31 simplified_df_cefr_labeled.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 213539545 May 19 05:50 wiki_cefr_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "%ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6397883f-94b0-42fd-81ca-82f4e2f55e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob(bucket_name = BUCKET_NAME, \n",
    "              source_blob_name = MODEL_BLOB_NAME, \n",
    "              destination_file_name = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9bc39b-c05f-4627-92ae-6486e77c74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob(bucket_name = BUCKET_NAME, \n",
    "              source_blob_name = PREPROC_BLOB_NAME, \n",
    "              destination_file_name = PREPROC_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7446a2e-7c48-45a4-9786-ad9ee26089a3",
   "metadata": {},
   "source": [
    "### CEFR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737e03d0-b165-45ea-9399-d35d31244134",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/tmp/ipykernel_2087/1088920131.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mktrain\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/ktrain/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mimports\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mutils\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mU\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m from .core import (\n\u001B[1;32m      4\u001B[0m     \u001B[0mArrayLearner\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mGenLearner\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/ktrain/imports.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \u001B[0mACC_NAME\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mVAL_ACC_NAME\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"val_accuracy\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m         \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0mK\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtyping\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_typing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;31m# TensorFlow Debugger (tfdbg).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcheck_numerics_callback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    131\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdumping_callback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgen_debug_ops\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/debug/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;31m# pylint: disable=unused-imports\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug_data\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDebugDumpDir\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug_data\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDebugTensorDatum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug_data\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mhas_inf_or_nan\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158417d-1eb8-4879-aab4-0bcb45e98cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.load_predictor(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f1cf0-fd7b-4774-a752-e4dc96082b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = predictor.predict(list(df_long[\"generated_text\"]))\n",
    "df_long[\"cefr_labels\"] = [label.split(\"_\")[1] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bac5f-00f5-4ae0-8fca-97b0883ed6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Run this cell only if source-target cefr labels are not generated in raw df \n",
    "\n",
    "no_raw_cefr = True\n",
    "\n",
    "if(no_raw_cefr):\n",
    "    \n",
    "    ## Source\n",
    "    source_labels = predictor.predict(list(df_long[\"source\"]))\n",
    "    df_long[\"source_level_cefr\"] = [label.split(\"_\")[1] for label in source_labels]\n",
    "    \n",
    "    ## Target\n",
    "    target_labels = predictor.predict(list(df_long[\"target\"]))\n",
    "    df_long[\"target_level_cefr\"] = [label.split(\"_\")[1] for label in target_labels]\n",
    "    \n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd779f98-002e-4e24-9dd7-ec599a927ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://simplified_df_cefr_labeled.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  5.7 MiB/  5.7 MiB]                                                \n",
      "Operation completed over 1 objects/5.7 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "if(1):\n",
    "    \n",
    "    ## Save to .csv\n",
    "    df_long.to_csv(\"simplified_df_cefr_labeled.csv\", index=False)\n",
    "    \n",
    "    ## Save to GC bucket\n",
    "    !gsutil cp -r simplified_df_cefr_labeled.csv gs://XXX/Text_Simplification/simplified_df_cefr_labeled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07a409-66aa-43bf-a1af-47de5bf9cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'target', 'source_level_og', 'target_level_og', 'data_source',\n",
       "       'id', 'source_level_cefr', 'target_level_cefr', 'model', 'prompt',\n",
       "       'generated_text', 'cefr_labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de645784-a23e-464a-a579-fafb21e95f8a",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb7d69-3602-4dc4-a6ed-a9a468f7475a",
   "metadata": {},
   "source": [
    "### Scoring rules\n",
    "\n",
    "* \"Simplify\": If source_level_og is 3 or 2, and the cefr_labels level is less than source_level_og, consider it a correct simplification.\n",
    "* \"Simplify to elementary level\", \"Simplify to CEFR A1\": If source_level_og is 3 or 2, and the cefr_labels level is 1, consider it a correct simplification.\n",
    "* \"Simplify to intermediate level\", \"Simplify to CEFR B1\": If source_level_og is 3, and the cefr_labels level is 2, consider it a correct simplification.\n",
    "* If source_level_og is 3 or 2, and cefr_labels is equal to source_level_og, consider it an incorrect simplification, but keep a count of such instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45cdb5a-f9be-4eb8-bff3-7721171b000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.read_csv(\"simplified_df_cefr_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b61e2b0-483c-4a38-a9f5-987d4dab88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.dropna(subset=['source_level_og'])\n",
    "\n",
    "df_long['cefr_labels'] = df_long['cefr_labels'].astype(int)\n",
    "df_long['source_level_og'] = df_long['source_level_og'].astype(int)\n",
    "# df_long['source_level_cefr'] = df_long['source_level_cefr'].astype(int)\n",
    "\n",
    "def check_correct_simplification(row):\n",
    "    source_level = row['source_level_og']\n",
    "    cefr_level = row['cefr_labels']\n",
    "    prompt = row['prompt']\n",
    "\n",
    "    # Level mapping for different prompts\n",
    "    level_mapping = {\n",
    "        \"Simplify\": source_level - 1, \n",
    "        \"Simplify to elementary level\": 1, \n",
    "        \"Simplify to CEFR A1\": 1, \n",
    "        \"Simplify to intermediate level\": 2, \n",
    "        \"Simplify to CEFR B1\": 2,\n",
    "    }\n",
    "\n",
    "    if source_level in [3, 2]:\n",
    "        if prompt == \"Simplify\":\n",
    "            return (source_level == 3 and cefr_level == 2) or cefr_level == 1\n",
    "        elif prompt in level_mapping:\n",
    "            # Check if correct simplification\n",
    "            return cefr_level == level_mapping[prompt]\n",
    "        elif cefr_level == source_level:\n",
    "            # For the case when level stays the same\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "# Add 'correct_simplification' column\n",
    "df_long['correct_simplification'] = df_long.apply(check_correct_simplification, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "406e25c8-f676-48b8-8024-ed97c9ecfcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model                          Prompt  Score for source level 2  \\\n",
      "0   dolly                        Simplify                    0.6500   \n",
      "1   dolly             Simplify to CEFR A1                    0.5750   \n",
      "2   dolly             Simplify to CEFR B1                    0.1750   \n",
      "3   dolly    Simplify to elementary level                    0.6500   \n",
      "4   dolly  Simplify to intermediate level                    0.1625   \n",
      "5  flant5                        Simplify                    0.6375   \n",
      "6  flant5             Simplify to CEFR A1                    0.6125   \n",
      "7  flant5             Simplify to CEFR B1                    0.0500   \n",
      "8  flant5    Simplify to elementary level                    0.5750   \n",
      "9  flant5  Simplify to intermediate level                    0.1625   \n",
      "\n",
      "   Score for source level 3  \n",
      "0                   0.92500  \n",
      "1                   0.48750  \n",
      "2                   0.37500  \n",
      "3                   0.63750  \n",
      "4                   0.30000  \n",
      "5                   0.87500  \n",
      "6                   0.65000  \n",
      "7                   0.31875  \n",
      "8                   0.62500  \n",
      "9                   0.33125  \n",
      "\n",
      "Count of instances where CEFR level is the same as source level out of 300:\n",
      "model   prompt                        \n",
      "dolly   Simplify                          18\n",
      "        Simplify to CEFR A1               20\n",
      "        Simplify to CEFR B1               14\n",
      "        Simplify to elementary level      15\n",
      "        Simplify to intermediate level    13\n",
      "flant5  Simplify                          13\n",
      "        Simplify to CEFR A1                5\n",
      "        Simplify to CEFR B1                4\n",
      "        Simplify to elementary level      12\n",
      "        Simplify to intermediate level    13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute scores\n",
    "scores = df_long.groupby(['model', 'prompt', 'source_level_og'])['correct_simplification'].mean().unstack().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "scores.columns = ['Model', 'Prompt', 'Score for source level 2', 'Score for source level 3']\n",
    "\n",
    "# Count of instances where CEFR level stays the same as source level\n",
    "same_level_count = df_long[df_long['cefr_labels'] == df_long['source_level_og']].groupby(['model', 'prompt']).size()\n",
    "\n",
    "# Print results\n",
    "print(scores)\n",
    "print(f\"\\nCount of instances where CEFR level is the same as source level out of {df.shape[0]}:\")\n",
    "print(same_level_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f48012-4726-4c6c-a2c5-389a9d91a1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ab926-f216-4024-98dd-dad2cc6edbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89b6596-3ace-4ec4-a15a-8639285c5701",
   "metadata": {},
   "source": [
    "#### Using source_level_cefr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3572e11-5913-4387-b674-7fe087e3e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct_simplification(row):\n",
    "    source_level = row['source_level_cefr']\n",
    "    cefr_level = row['cefr_labels']\n",
    "    prompt = row['prompt']\n",
    "\n",
    "    # Level mapping for different prompts\n",
    "    level_mapping = {\n",
    "        \"Simplify\": source_level - 1, \n",
    "        \"Simplify to elementary level\": 1, \n",
    "        \"Simplify to CEFR A1\": 1, \n",
    "        \"Simplify to intermediate level\": 2, \n",
    "        \"Simplify to CEFR B1\": 2,\n",
    "    }\n",
    "\n",
    "    if source_level in [3, 2]:\n",
    "        if prompt in level_mapping:\n",
    "            # Check if correct simplification\n",
    "            return cefr_level == level_mapping[prompt]\n",
    "        elif cefr_level == source_level:\n",
    "            # For the case when level stays the same\n",
    "            return False\n",
    "    return None\n",
    "\n",
    "# Add 'correct_simplification' column\n",
    "df_long['correct_simplification'] = df_long.apply(check_correct_simplification, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "711fbdab-8f06-471b-b6e3-b1fec7b9cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_level_cefr   model                        prompt   1         2\n",
      "0                   dolly                      Simplify NaN  0.769231\n",
      "1                   dolly           Simplify to CEFR A1 NaN  0.743590\n",
      "2                   dolly  Simplify to elementary level NaN  0.794872\n",
      "3                  flant5                      Simplify NaN  0.512821\n",
      "4                  flant5           Simplify to CEFR A1 NaN  0.461538\n",
      "5                  flant5           Simplify to CEFR B1 NaN  0.461538\n",
      "6                  flant5  Simplify to elementary level NaN  0.589744\n",
      "\n",
      "Count of instances where CEFR level is the same as source level:\n",
      "model   prompt                      \n",
      "dolly   Simplify                        27\n",
      "        Simplify to CEFR A1             22\n",
      "        Simplify to elementary level    24\n",
      "flant5  Simplify                        30\n",
      "        Simplify to CEFR A1             27\n",
      "        Simplify to CEFR B1             33\n",
      "        Simplify to elementary level    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute scores\n",
    "scores = df_long.groupby(['model', 'prompt', 'source_level_cefr'])['correct_simplification'].mean().unstack().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "# scores.columns = ['Model', 'Prompt', 'Score for source level 2', 'Score for source level 3']\n",
    "\n",
    "# Count of instances where CEFR level stays the same as source level\n",
    "same_level_count = df_long[df_long['cefr_labels'] == df_long['source_level_cefr']].groupby(['model', 'prompt']).size()\n",
    "\n",
    "# Print results\n",
    "print(scores)\n",
    "print(\"\\nCount of instances where CEFR level is the same as source level:\")\n",
    "print(same_level_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5dd0a1b0-1e37-44dd-b869-7cfd57142abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    273\n",
       "1    147\n",
       "Name: source_level_cefr, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long['source_level_cefr'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
