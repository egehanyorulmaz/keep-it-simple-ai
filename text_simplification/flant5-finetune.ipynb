{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d078f93c-ee7a-4d8a-966b-9b609d95b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "# %pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# %pip install transformers datasets evaluate rouge-score nltk py7zr\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002e547d-3c40-422a-b375-4eafea111af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da434820-b45b-4115-b114-2d428ee701a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efade5ae-736b-4919-914d-e8d177448803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d4252-d707-432b-a25e-72774169d8a3",
   "metadata": {},
   "source": [
    "## Notebook param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bac341f-d899-4f67-bc7a-51ad390e2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = './cache_mod'\n",
    "SEED = 0\n",
    "N_SAMPLES = 1000\n",
    "model_name = \"google/flan-t5-base\"\n",
    "# dataset_name = \"samsum\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70461413-74ad-4e55-bdb5-25e3d4a2d42a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a2403b-a57d-4637-9a4c-337894c41dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12910"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Text_Simplification/raw_data.csv\")\n",
    "\n",
    "sources = [\"BreakingNewsEnglish\",\"NewsInLevels\"]\n",
    "df1 = df[df[\"data_source\"].isin(sources)]\n",
    "\n",
    "df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654fb07b-91b1-4c1c-a20b-b33349f049da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>data_source</th>\n",
       "      <th>data_type</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>British people are big tea drinkers. It is a t...</td>\n",
       "      <td>British people love tea. They drink it for dif...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  British people are big tea drinkers. It is a t...   \n",
       "\n",
       "                                              target  source_level_og  \\\n",
       "0  British people love tea. They drink it for dif...              3.0   \n",
       "\n",
       "   target_level_og          data_source            data_type  \\\n",
       "0              2.0  BreakingNewsEnglish  text_simplification   \n",
       "\n",
       "   source_level_cefr  target_level_cefr           id  \n",
       "0                NaN                NaN  TS000000001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01cde20-5316-434b-984d-2501415e49ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12910"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1\n",
    "# df2 = df1.sample(1000)\n",
    "\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d50e9-88a5-4531-a98c-9f380c59050f",
   "metadata": {},
   "source": [
    "## Tokenizer, Model and Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3b86c4-a571-438c-bd89-c4db8710f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb015f4-20fd-44cb-acfb-518f44f75ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be fine-tuning the `google/flan-t5-large` model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1fefba-c3be-4827-8c40-884aa9fc8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge will be used to evaluate simplification\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "## TODO@Prayut: Use Flesch-Kincaid or SMOG Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8a556-ddc1-42a9-a3a3-483b1433e459",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e59dddc-3c21-4394-bc5e-f8638a12fd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'source_level_og', 'target', 'target_level_og', '__index_level_0__'],\n",
       "        num_rows: 10457\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'source_level_og', 'target', 'target_level_og', '__index_level_0__'],\n",
       "        num_rows: 1162\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'source_level_og', 'target', 'target_level_og', '__index_level_0__'],\n",
       "        num_rows: 1291\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2[['source','source_level_og','target','target_level_og']]\n",
    "\n",
    "df_train, df_test = train_test_split(df3, test_size=0.1, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "val_dataset = Dataset.from_pandas(df_val)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b16a56e-9ace-42de-89e3-35326953e998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10457\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1162\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1291\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_fn(examples):\n",
    "        # t5 input requires a prompt prefix that specifies the task\n",
    "        prefixed_input = [\"Simplify from \" + str(source_level) + \" to \" + str(target_level) + \" : \" + source for source, source_level, target_level in zip(examples[\"source\"], examples['source_level_og'], examples['target_level_og'])]\n",
    "\n",
    "        # tokenize inputs\n",
    "        # note that padding is left out here because it will be left to the data collator\n",
    "        model_inputs = tokenizer(prefixed_input, truncation=True, padding=False)\n",
    "\n",
    "        # tokenizing labels using `text_target` argument\n",
    "        # note that padding is left out here because it will be left to the data collator\n",
    "        labels = tokenizer(examples[\"target\"], truncation=True, padding=False)\n",
    "\n",
    "        # `labels` is a required name for pytorch evaluation\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        \n",
    "        return model_inputs \n",
    "    \n",
    "# applying preprocess function to entire dataset\n",
    "# note 1: had the tokenizers had padding=True, all observations in the dataset would have been padded/truncatd to the same length, regardless of how they are batched\n",
    "# note 2: this creates new column, and the `map` method takes an arguments to remove unneeded columns\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=['source', 'source_level_og', 'target', 'target_level_og', '__index_level_0__'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20c865b-ff53-4500-b7cb-c4ce7ace2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~original inputs~~~~~\n",
      "Italian authorities released footage of daring night time raids to dismantle the Sicilian Mafia.\n",
      "The police used cover surveillance and wiretaps to monitor multiple suspects who they suspect of Mafia association, extortion and weapons violations. In total, they arrested 46 people, including a presumed new regional boss.\n",
      "\n",
      "~~~~encoded inputs~~~~~\n",
      "[180, 10296, 4921, 45, 1877, 632, 12, 3, 12734, 3, 10, 4338, 5779, 1883, 13420, 13, 649, 53, 706, 97, 15941, 7, 12, 1028, 348, 17, 109, 8, 29250, 23, 152, 1534, 89, 23, 9, 5, 37, 2095, 261, 1189, 12305, 11, 4107, 8873, 7, 12, 3393, 1317, 6220, 7, 113, 79, 6220, 13, 1534, 89, 23, 9, 6028, 6, 3, 10398, 127, 1575, 11, 7749, 17880, 5, 86, 792, 6, 79, 10195, 9668, 151, 6, 379, 3, 9, 26451, 26, 126, 3518, 7930, 5, 3, 1]\n",
      "~~~~decoded inputs~~~~~\n",
      "Simplify from 3.0 to 1.0 : Italian authorities released footage of daring night time raids to dismantle the Sicilian Mafia. The police used cover surveillance and wiretaps to monitor multiple suspects who they suspect of Mafia association, extortion and weapons violations. In total, they arrested 46 people, including a presumed new regional boss. </s>\n",
      "~~~~encoded targets~~~~~\n",
      "[29250, 63, 19, 16, 5308, 5, 37, 29250, 23, 152, 1534, 89, 23, 9, 19, 132, 5, 37, 29250, 23, 152, 2095, 2870, 8, 1534, 89, 23, 9, 5, 37, 2095, 3393, 7, 151, 5, 37, 2095, 10375, 3075, 13, 15941, 7, 5, 328, 10319, 9668, 151, 5, 3, 1]\n",
      "~~~~decoded target~~~~~\n",
      "Sicily is in Italy. The Sicilian Mafia is there. The Sicilian police fight the Mafia. The police monitors people. The police releases videos of raids. They arrest 46 people. </s>\n",
      "~~~~sample length in batch~~~~~\n",
      "[87, 117]\n"
     ]
    }
   ],
   "source": [
    "# giving example of how data looks raw, then tokenized, then decoded\n",
    "# note again, there is no padding here\n",
    "sample = tokenized_dataset[\"train\"][25:27]\n",
    "\n",
    "print(\"~~~~original inputs~~~~~\")\n",
    "print(dataset[\"train\"][\"source\"][25])\n",
    "\n",
    "print(\"~~~~encoded inputs~~~~~\")\n",
    "print(sample[\"input_ids\"][0])\n",
    "\n",
    "print(\"~~~~decoded inputs~~~~~\")\n",
    "print(tokenizer.decode(sample[\"input_ids\"][0]))\n",
    "\n",
    "print(\"~~~~encoded targets~~~~~\")\n",
    "print(sample[\"labels\"][0])\n",
    "\n",
    "print(\"~~~~decoded target~~~~~\")\n",
    "print(tokenizer.decode(sample[\"labels\"][0]))\n",
    "\n",
    "print(\"~~~~sample length in batch~~~~~\")\n",
    "print([len(x) for x in sample[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601bd10-b690-4584-bf3a-244144bae853",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "535d56c2-432b-40ca-b5e4-269da77efd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO@Prayut: Modify this later to use appropriate metric for simplification tasks\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # predictions have to be decoded into tokens\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # returns a dictionary metric: score pairs\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    # Extract a few results\n",
    "    result = {key: value for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length, will be shown during training loop output\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c35a5-32e4-4cc9-97f2-7d7553f549ae",
   "metadata": {},
   "source": [
    "## Prep for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69bc1065-2111-4c8b-aecd-8b42ffeb770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically padding the inputs for each batch, as oppose to padding to the max of the entire dataset\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model_name,\n",
    "    padding=True,\n",
    "    label_pad_token_id=-100 # pytorch ignores during loss when label ids are -100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48bef5d4-ee7c-44e0-bbe5-daf0c207610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"flan-t5-base-tune/\",\n",
    "    per_device_train_batch_size=8, # important for avoiding OOM\n",
    "    per_device_eval_batch_size=8, # important for avoiding OOM\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, # setting to true here produces NaNs in evaluation for some reason\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ddf5a0f-f619-402c-9301-7cf8e379a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating smaller training and test samples to speed up training\n",
    "# this is optional, though recommended to see if testing is working without errors before scaling up ot full dataset\n",
    "small_train = tokenized_dataset[\"train\"].shuffle(seed=SEED).select(range(500))\n",
    "small_test = tokenized_dataset[\"test\"].shuffle(seed=SEED).select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83bbff53-b55b-4b3e-af24-4cf2686a06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=small_train, # replace with tokenized_dataset[\"train\"] if want to use full dataset\n",
    "    eval_dataset=small_test, # replace with tokenized_dataset[\"test\"] if want to use full dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec36a4-3b6a-4ef8-ad3c-e09e412c6bef",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3720caa-1bab-455f-9c18-7bbe98910db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 315\n",
      "  Number of trainable parameters = 247577856\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "result = trainer.train()\n",
    "\n",
    "print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe27e5-4147-4d85-9572-930600411f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating best model on the test set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54eaf6-6a20-4b3f-a147-42117fd4ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model to local directory\n",
    "trainer.save_model(\"flan-t5-based-tuned-to-max\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
