{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454ebb4e-b94e-4818-ab07-335a2c4212a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2ab32-e883-4c98-bc7c-adca86fbc729",
   "metadata": {},
   "source": [
    "## Define checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa55d818-bd77-4016-8b36-33e025c72fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './cache_mod'\n",
    "checkpoint_t5 = \"google/flan-t5-large\"\n",
    "checkpoint_dolly = \"databricks/dolly-v2-2-8b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033b5fc2-5a66-46ab-ae34-90b68be4600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, prompt, is_pipeline=False, max_new_tokens=100):\n",
    "    if is_pipeline:\n",
    "        return model(prompt)[0]['generated_text']\n",
    "    else:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "        result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ccd6-fdb9-4cbc-b934-e74b408a959b",
   "metadata": {},
   "source": [
    "## Read sample data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b5b8ca-7666-406a-855d-cc33e68deb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og.1</th>\n",
       "      <th>target_level_og.1</th>\n",
       "      <th>data_source.1</th>\n",
       "      <th>data_type</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1587</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1749</td>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000001750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data_source  source_level_og  target_level_og  Unnamed: 3  \\\n",
       "0  BreakingNewsEnglish              2.0              1.0        1587   \n",
       "1  BreakingNewsEnglish              2.0              1.0        1749   \n",
       "\n",
       "                                              source  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "\n",
       "                                              target  source_level_og.1  \\\n",
       "0  Donald Trump is interested in buying Greenland...                2.0   \n",
       "1  Everyone knows children don't like eating gree...                2.0   \n",
       "\n",
       "   target_level_og.1        data_source.1            data_type  \\\n",
       "0                1.0  BreakingNewsEnglish  text_simplification   \n",
       "1                1.0  BreakingNewsEnglish  text_simplification   \n",
       "\n",
       "   source_level_cefr  target_level_cefr           id  \n",
       "0                NaN                NaN  TS000001588  \n",
       "1                NaN                NaN  TS000001750  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Text_Simplification/trial_smpl_medium.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69792c96-1627-44b8-95f8-de188dfa8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55624d-0191-4e11-ae9e-007d83592c29",
   "metadata": {},
   "source": [
    "## Run simplification for various prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a1845-9b7f-4bff-ac7d-4ab2c2849c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Running dolly...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prompts = [\"Simplify\",\"Simplify to elementary level\",\"Simplify to CEFR A1\",\"Simplify to intermediate level\", \"Simplify to CEFR B1\"]\n",
    "\n",
    "model_checkpoints = {\n",
    "    'dolly': checkpoint_dolly,\n",
    "    'flant5': checkpoint_t5\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, checkpoint in model_checkpoints.items():\n",
    "    if checkpoint == checkpoint_dolly:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        model = pipeline(model=checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n",
    "        is_pipeline = True\n",
    "        print(\"Running dolly...\")\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, cache_dir=cache_dir)\n",
    "        is_pipeline = False\n",
    "        print(\"Running t5...\")\n",
    "\n",
    "    for inst in prompts:\n",
    "        df[f\"{model_name}-{inst}\"] = df['source'].apply(lambda x: generate_text(model, tokenizer, inst + ': ' + x, is_pipeline=is_pipeline))\n",
    "        \n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b534f0-0f6b-4a01-b851-1992bad8ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Text_Simplification/simplified_df_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7680466-f7e8-4394-b87c-6abaae14ec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
