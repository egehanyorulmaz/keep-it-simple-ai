{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4483c6-f5ee-4812-aaaa-0b282c140174",
   "metadata": {},
   "source": [
    "### Fine-tuning LLama 2 with QLoRA\n",
    "https://blog.ovhcloud.com/fine-tuning-llama-2-models-using-a-single-gpu-qlora-and-ai-notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9622d6-6105-499a-a3e5-921a1288b5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.1)\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements_ovhcloud.txt\n",
    "!pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fa3de9-9a50-44f8-8970-bc5941b3c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LSB modules are available.\n",
      "Distributor ID:\tDebian\n",
      "Description:\tDebian GNU/Linux 11 (bullseye)\n",
      "Release:\t11\n",
      "Codename:\tbullseye\n"
     ]
    }
   ],
   "source": [
    "!lsb_release -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71832104-9f40-4c40-90d6-8858d981d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f2a5f9-ca7b-4871-bd5a-e29abbf5dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo chmod 777 /root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f29f14-c65c-4f96-9e6d-9a291cf1d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset, Dataset\n",
    "from functools import partial\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1231971-178d-40e1-a91c-e8520de2408c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858de0fb-4da7-4d01-8da7-4cc056394148",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891f6f1b-1c64-4a1b-a133-31f397e461c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>data_source</th>\n",
       "      <th>data_type</th>\n",
       "      <th>source_level_cefr</th>\n",
       "      <th>target_level_cefr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>British people are big tea drinkers. It is a t...</td>\n",
       "      <td>British people love tea. They drink it for dif...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many people around the world stay at home and ...</td>\n",
       "      <td>Many people stay at home. They do not want to ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most of us don't really take much notice of ca...</td>\n",
       "      <td>We rarely notice car license plates. Maybe we ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy's ruling party may introduce a new law t...</td>\n",
       "      <td>Italy wants to stop people using English words...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people are very forgetful, while others c...</td>\n",
       "      <td>Some people are forgetful, while others rememb...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS000000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  British people are big tea drinkers. It is a t...   \n",
       "1  Many people around the world stay at home and ...   \n",
       "2  Most of us don't really take much notice of ca...   \n",
       "3  Italy's ruling party may introduce a new law t...   \n",
       "4  Some people are very forgetful, while others c...   \n",
       "\n",
       "                                              target  source_level_og  \\\n",
       "0  British people love tea. They drink it for dif...              3.0   \n",
       "1  Many people stay at home. They do not want to ...              3.0   \n",
       "2  We rarely notice car license plates. Maybe we ...              3.0   \n",
       "3  Italy wants to stop people using English words...              3.0   \n",
       "4  Some people are forgetful, while others rememb...              3.0   \n",
       "\n",
       "   target_level_og          data_source            data_type  \\\n",
       "0              2.0  BreakingNewsEnglish  text_simplification   \n",
       "1              2.0  BreakingNewsEnglish  text_simplification   \n",
       "2              2.0  BreakingNewsEnglish  text_simplification   \n",
       "3              2.0  BreakingNewsEnglish  text_simplification   \n",
       "4              2.0  BreakingNewsEnglish  text_simplification   \n",
       "\n",
       "   source_level_cefr  target_level_cefr           id  \n",
       "0                NaN                NaN  TS000000001  \n",
       "1                NaN                NaN  TS000000002  \n",
       "2                NaN                NaN  TS000000003  \n",
       "3                NaN                NaN  TS000000004  \n",
       "4                NaN                NaN  TS000000005  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"gs://XXX/Text_Simplification/simplified_df_cefr_labeled.csv\"\n",
    "PATH = \"gs://XXX/raw_data.csv\"\n",
    "\n",
    "data = pd.read_csv(PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bff9f5f-506f-4f12-8c13-a59b7b4210d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791159"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783ad7fc-50f5-45fb-94ee-0dd81197dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"source_level_cefr\", \"target_level_cefr\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49df3e72-5179-4098-8f61-79d5a05507f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before dropping nan 791159\n",
      "Length after dropping nan 12910\n"
     ]
    }
   ],
   "source": [
    "print(\"Length before dropping nan\", len(data))\n",
    "data.dropna(subset=['target_level_og', 'source_level_og'], inplace=True)\n",
    "print(\"Length after dropping nan\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a4d422-16d2-4395-a008-50f38a0fd732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cefr_mapping\n",
       "2.0->1.0    4304\n",
       "3.0->2.0    4303\n",
       "3.0->1.0    4303\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cefr_mapping\"] = data[\"source_level_og\"].astype(str) + \"->\" + data[\"target_level_og\"].astype(str)\n",
    "data[\"cefr_mapping\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef3b805-6e74-40d7-8a28-606e46441b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_level_og</th>\n",
       "      <th>target_level_og</th>\n",
       "      <th>data_source</th>\n",
       "      <th>data_type</th>\n",
       "      <th>id</th>\n",
       "      <th>cefr_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>British people are big tea drinkers. It is a tradition in Britain to drink tea for different occasions and reasons. People have it for breakfast, ...</td>\n",
       "      <td>British people love tea. They drink it for different reasons – for breakfast, to give to guests, for tea breaks at work, and even when talking abo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000000001</td>\n",
       "      <td>3.0-&gt;2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many people around the world stay at home and do not want to go out. They cut themselves off from the world outside. They are recluses … people wh...</td>\n",
       "      <td>Many people stay at home. They do not want to go out and shut themselves off from the world. They do not want to meet other people. They are reclu...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000000002</td>\n",
       "      <td>3.0-&gt;2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most of us don't really take much notice of car license plates. Maybe we should look at them more from now because they may be valuable. One licen...</td>\n",
       "      <td>We rarely notice car license plates. Maybe we should because some are valuable. A license plate just sold for $15 million in Dubai. It had the let...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000000003</td>\n",
       "      <td>3.0-&gt;2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy's ruling party may introduce a new law to stop people using English words in Italian. People could get fined for using English and other non...</td>\n",
       "      <td>Italy wants to stop people using English words in Italian. People could get a fine for using non-Italian words. A government spokesperson is worri...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000000004</td>\n",
       "      <td>3.0-&gt;2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people are very forgetful, while others can remember everything they have done. Scientists know a lot about how our brains store and remember...</td>\n",
       "      <td>Some people are forgetful, while others remember everything. Scientists know how the brain remembers things. There is little research on how it fo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BreakingNewsEnglish</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000000005</td>\n",
       "      <td>3.0-&gt;2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "      <td>People in Paris enjoyed zip-lining off the Eiffel Tower. There was another zip-line before, but it was only from the first floor.\\r\\nThe new zip-l...</td>\n",
       "      <td>This week, there is a zip-line off the Eiffel Tower. People jump from the second floor of the tower. They go almost 100 kilometres per hour. They ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NewsInLevels</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000017373</td>\n",
       "      <td>2.0-&gt;1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17365</th>\n",
       "      <td>Over 200 dancers took part in an event in England. They put on old clothing, fake blood, and painted their faces white to look like zombies.\\r\\nTh...</td>\n",
       "      <td>This news is from England. An event is held there. Around 200 people come. They wear old clothing, and they put fake blood on their faces. They lo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NewsInLevels</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000017374</td>\n",
       "      <td>2.0-&gt;1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17366</th>\n",
       "      <td>A zoo in Indonesia was starving its animals, and it closed in 2016 after an elephant died. Now, the zoo is under heavy criticism again.\\r\\nThere i...</td>\n",
       "      <td>This news is about a zoo. It is in Indonesia. The zoo has problems. People there do not give enough food to the animals. An elephant dies. The zoo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NewsInLevels</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000017375</td>\n",
       "      <td>2.0-&gt;1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17367</th>\n",
       "      <td>At a zoo in Barcelona, Spain, a mother zebra gave birth and its baby zebra fell into a pond in their exhibit. Two zookeepers moved into the pond t...</td>\n",
       "      <td>This happens at a zoo in Barcelona, Spain. A mother zebra gives birth. The baby zebra falls into a pond in the exhibit. Two zookeepers go into the...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NewsInLevels</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000017376</td>\n",
       "      <td>2.0-&gt;1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>Mark Zuckerberg spent two days at Congress last week where he answered the senators’ questions about Facebook. He also said ‘sorry’ for privacy br...</td>\n",
       "      <td>There are some problems with Facebook. One problem is privacy. There are breaches in privacy.\\r\\nMark Zuckerberg is the CEO of Facebook. He comes ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NewsInLevels</td>\n",
       "      <td>text_simplification</td>\n",
       "      <td>TS000017377</td>\n",
       "      <td>2.0-&gt;1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12910 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      source  \\\n",
       "0      British people are big tea drinkers. It is a tradition in Britain to drink tea for different occasions and reasons. People have it for breakfast, ...   \n",
       "1      Many people around the world stay at home and do not want to go out. They cut themselves off from the world outside. They are recluses … people wh...   \n",
       "2      Most of us don't really take much notice of car license plates. Maybe we should look at them more from now because they may be valuable. One licen...   \n",
       "3      Italy's ruling party may introduce a new law to stop people using English words in Italian. People could get fined for using English and other non...   \n",
       "4      Some people are very forgetful, while others can remember everything they have done. Scientists know a lot about how our brains store and remember...   \n",
       "...                                                                                                                                                      ...   \n",
       "17364  People in Paris enjoyed zip-lining off the Eiffel Tower. There was another zip-line before, but it was only from the first floor.\\r\\nThe new zip-l...   \n",
       "17365  Over 200 dancers took part in an event in England. They put on old clothing, fake blood, and painted their faces white to look like zombies.\\r\\nTh...   \n",
       "17366  A zoo in Indonesia was starving its animals, and it closed in 2016 after an elephant died. Now, the zoo is under heavy criticism again.\\r\\nThere i...   \n",
       "17367  At a zoo in Barcelona, Spain, a mother zebra gave birth and its baby zebra fell into a pond in their exhibit. Two zookeepers moved into the pond t...   \n",
       "17368  Mark Zuckerberg spent two days at Congress last week where he answered the senators’ questions about Facebook. He also said ‘sorry’ for privacy br...   \n",
       "\n",
       "                                                                                                                                                      target  \\\n",
       "0      British people love tea. They drink it for different reasons – for breakfast, to give to guests, for tea breaks at work, and even when talking abo...   \n",
       "1      Many people stay at home. They do not want to go out and shut themselves off from the world. They do not want to meet other people. They are reclu...   \n",
       "2      We rarely notice car license plates. Maybe we should because some are valuable. A license plate just sold for $15 million in Dubai. It had the let...   \n",
       "3      Italy wants to stop people using English words in Italian. People could get a fine for using non-Italian words. A government spokesperson is worri...   \n",
       "4      Some people are forgetful, while others remember everything. Scientists know how the brain remembers things. There is little research on how it fo...   \n",
       "...                                                                                                                                                      ...   \n",
       "17364  This week, there is a zip-line off the Eiffel Tower. People jump from the second floor of the tower. They go almost 100 kilometres per hour. They ...   \n",
       "17365  This news is from England. An event is held there. Around 200 people come. They wear old clothing, and they put fake blood on their faces. They lo...   \n",
       "17366  This news is about a zoo. It is in Indonesia. The zoo has problems. People there do not give enough food to the animals. An elephant dies. The zoo...   \n",
       "17367  This happens at a zoo in Barcelona, Spain. A mother zebra gives birth. The baby zebra falls into a pond in the exhibit. Two zookeepers go into the...   \n",
       "17368  There are some problems with Facebook. One problem is privacy. There are breaches in privacy.\\r\\nMark Zuckerberg is the CEO of Facebook. He comes ...   \n",
       "\n",
       "       source_level_og  target_level_og          data_source  \\\n",
       "0                  3.0              2.0  BreakingNewsEnglish   \n",
       "1                  3.0              2.0  BreakingNewsEnglish   \n",
       "2                  3.0              2.0  BreakingNewsEnglish   \n",
       "3                  3.0              2.0  BreakingNewsEnglish   \n",
       "4                  3.0              2.0  BreakingNewsEnglish   \n",
       "...                ...              ...                  ...   \n",
       "17364              2.0              1.0         NewsInLevels   \n",
       "17365              2.0              1.0         NewsInLevels   \n",
       "17366              2.0              1.0         NewsInLevels   \n",
       "17367              2.0              1.0         NewsInLevels   \n",
       "17368              2.0              1.0         NewsInLevels   \n",
       "\n",
       "                 data_type           id cefr_mapping  \n",
       "0      text_simplification  TS000000001     3.0->2.0  \n",
       "1      text_simplification  TS000000002     3.0->2.0  \n",
       "2      text_simplification  TS000000003     3.0->2.0  \n",
       "3      text_simplification  TS000000004     3.0->2.0  \n",
       "4      text_simplification  TS000000005     3.0->2.0  \n",
       "...                    ...          ...          ...  \n",
       "17364  text_simplification  TS000017373     2.0->1.0  \n",
       "17365  text_simplification  TS000017374     2.0->1.0  \n",
       "17366  text_simplification  TS000017375     2.0->1.0  \n",
       "17367  text_simplification  TS000017376     2.0->1.0  \n",
       "17368  text_simplification  TS000017377     2.0->1.0  \n",
       "\n",
       "[12910 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7795166b-d730-4c28-8606-dd6c55a751a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cefr_to_text(language_level):\n",
    "    if int(language_level) == 3:\n",
    "        return \"advanced\"\n",
    "    elif int(language_level) == 2:\n",
    "        return \"intermediate\"\n",
    "    elif int(language_level) == 1:\n",
    "        return \"beginner\"\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized language level\")\n",
    "        \n",
    "def generate_instruction_column(source_cefr, target_cefr):\n",
    "    source_level_text = map_cefr_to_text(source_cefr)\n",
    "    target_level_text = map_cefr_to_text(target_cefr)\n",
    "    return f\"Simplify the following text from {source_level_text} language level to {target_level_text} language level\"\n",
    "\n",
    "data[\"instruction\"] = data.apply(lambda row: generate_instruction_column(row[\"source_level_og\"], row[\"target_level_og\"]), axis=1)\n",
    "data[\"source_cefr_level\"] = [map_cefr_to_text(source_cefr) for source_cefr in data[\"source_level_og\"]]\n",
    "data[\"target_cefr_level\"] = [map_cefr_to_text(source_cefr) for source_cefr in data[\"target_level_og\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49cd5619-bdb9-4b5d-844f-bd18c116f19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9fa3260-011d-4a1c-9c7a-6580d40171f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simplify the following text from advanced language level to intermediate language level'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][\"instruction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b90c44-7153-4b50-963b-248e7c149047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename({'source': 'context', 'target': 'response'}, axis=1, inplace=True)\n",
    "data = data[[\"instruction\", \"context\", \"response\", \"source_cefr_level\", \"target_cefr_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626c0885-e974-49d1-a39d-4b86773bd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a dictionary\n",
    "data_dict = data.to_dict('list')\n",
    "\n",
    "# Convert the dictionary to a Hugging Face Dataset\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86b2bf9-5609-45da-86aa-85dbfac8f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'source_cefr_level', 'target_cefr_level'],\n",
       "    num_rows: 12910\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ddc696-c466-4d01-af19-a325ddda598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts: 12910\n",
      "Column names are: ['instruction', 'context', 'response', 'source_cefr_level', 'target_cefr_level']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of prompts: {len(dataset)}')\n",
    "print(f'Column names are: {dataset.column_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be684f6-5c19-41c2-afa5-98338989946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>source_cefr_level</th>\n",
       "      <th>target_cefr_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplify the following text from advanced language level to intermediate language level</td>\n",
       "      <td>British people are big tea drinkers. It is a tradition in Britain to drink tea for different occasions and reasons. People have it for breakfast, ...</td>\n",
       "      <td>British people love tea. They drink it for different reasons – for breakfast, to give to guests, for tea breaks at work, and even when talking abo...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simplify the following text from advanced language level to intermediate language level</td>\n",
       "      <td>Many people around the world stay at home and do not want to go out. They cut themselves off from the world outside. They are recluses … people wh...</td>\n",
       "      <td>Many people stay at home. They do not want to go out and shut themselves off from the world. They do not want to meet other people. They are reclu...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simplify the following text from advanced language level to intermediate language level</td>\n",
       "      <td>Most of us don't really take much notice of car license plates. Maybe we should look at them more from now because they may be valuable. One licen...</td>\n",
       "      <td>We rarely notice car license plates. Maybe we should because some are valuable. A license plate just sold for $15 million in Dubai. It had the let...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simplify the following text from advanced language level to intermediate language level</td>\n",
       "      <td>Italy's ruling party may introduce a new law to stop people using English words in Italian. People could get fined for using English and other non...</td>\n",
       "      <td>Italy wants to stop people using English words in Italian. People could get a fine for using non-Italian words. A government spokesperson is worri...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simplify the following text from advanced language level to intermediate language level</td>\n",
       "      <td>Some people are very forgetful, while others can remember everything they have done. Scientists know a lot about how our brains store and remember...</td>\n",
       "      <td>Some people are forgetful, while others remember everything. Scientists know how the brain remembers things. There is little research on how it fo...</td>\n",
       "      <td>advanced</td>\n",
       "      <td>intermediate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               instruction  \\\n",
       "0  Simplify the following text from advanced language level to intermediate language level   \n",
       "1  Simplify the following text from advanced language level to intermediate language level   \n",
       "2  Simplify the following text from advanced language level to intermediate language level   \n",
       "3  Simplify the following text from advanced language level to intermediate language level   \n",
       "4  Simplify the following text from advanced language level to intermediate language level   \n",
       "\n",
       "                                                                                                                                                 context  \\\n",
       "0  British people are big tea drinkers. It is a tradition in Britain to drink tea for different occasions and reasons. People have it for breakfast, ...   \n",
       "1  Many people around the world stay at home and do not want to go out. They cut themselves off from the world outside. They are recluses … people wh...   \n",
       "2  Most of us don't really take much notice of car license plates. Maybe we should look at them more from now because they may be valuable. One licen...   \n",
       "3  Italy's ruling party may introduce a new law to stop people using English words in Italian. People could get fined for using English and other non...   \n",
       "4  Some people are very forgetful, while others can remember everything they have done. Scientists know a lot about how our brains store and remember...   \n",
       "\n",
       "                                                                                                                                                response  \\\n",
       "0  British people love tea. They drink it for different reasons – for breakfast, to give to guests, for tea breaks at work, and even when talking abo...   \n",
       "1  Many people stay at home. They do not want to go out and shut themselves off from the world. They do not want to meet other people. They are reclu...   \n",
       "2  We rarely notice car license plates. Maybe we should because some are valuable. A license plate just sold for $15 million in Dubai. It had the let...   \n",
       "3  Italy wants to stop people using English words in Italian. People could get a fine for using non-Italian words. A government spokesperson is worri...   \n",
       "4  Some people are forgetful, while others remember everything. Scientists know how the brain remembers things. There is little research on how it fo...   \n",
       "\n",
       "  source_cefr_level target_cefr_level  \n",
       "0          advanced      intermediate  \n",
       "1          advanced      intermediate  \n",
       "2          advanced      intermediate  \n",
       "3          advanced      intermediate  \n",
       "4          advanced      intermediate  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad53a0ba-18a3-4468-aa48-fc78529ff6dd",
   "metadata": {},
   "source": [
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a13a1d7-7514-4bae-bcaa-139d2bda1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_formats(sample):\n",
    "    \"\"\"\n",
    "    Format various fields of the sample ('instruction', 'context', 'response')\n",
    "    Then concatenate them using two newline characters \n",
    "    :param sample: Sample dictionary\n",
    "    \"\"\"\n",
    "    SYSTEM_PROMPT = f\"\"\"<s>[INST] <<SYS>> \\n\n",
    "    You are a helpful, respectful and honest assistant. Always simplify the text to the asked target language level from the source language level, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "    <</SYS>>\\n\"\"\"\n",
    "    INSTRUCTION = f\"{sample['instruction']}: {sample['context']} [/INST] \\n\\n\"\n",
    "    RESPONSE = f\"Sure, I can certainly do that. The {sample['source_cefr_level']} language level text simplified to {sample['target_cefr_level']} language level is as follows: {sample['response']}\\n</s>\"     \n",
    "    formatted_prompt = SYSTEM_PROMPT + INSTRUCTION + RESPONSE\n",
    "    sample[\"text\"] = formatted_prompt\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e082d55-bc40-486d-a88b-8fa7a3feab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
    "def get_max_length(model):\n",
    "    conf = model.config\n",
    "    max_length = None\n",
    "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
    "        max_length = getattr(model.config, length_setting, None)\n",
    "        if max_length:\n",
    "            print(f\"Found max lenth: {max_length}\")\n",
    "            break\n",
    "    if not max_length:\n",
    "        max_length = 1024\n",
    "        print(f\"Using default max length: {max_length}\")\n",
    "    return max_length\n",
    "\n",
    "\n",
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Tokenizing a batch\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\n",
    "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset: str):\n",
    "    \"\"\"Format & tokenize it so it is ready for training\n",
    "    :param tokenizer (AutoTokenizer): Model Tokenizer\n",
    "    :param max_length (int): Maximum number of tokens to emit from tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add prompt to each sample\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    dataset = dataset.map(create_prompt_formats)#, batched=True)\n",
    "    \n",
    "    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n",
    "    _preprocessing_function = partial(preprocess_batch, max_length=max_length, \n",
    "                                      tokenizer=tokenizer)\n",
    "    dataset = dataset.map(\n",
    "        _preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"instruction\", \"context\", \"response\", \"text\", \"source_cefr_level\", \"target_cefr_level\"],\n",
    "    )\n",
    "\n",
    "    # Filter out samples that have input_ids exceeding max_length\n",
    "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
    "    \n",
    "    # Shuffle dataset\n",
    "    dataset = dataset.shuffle(seed=seed)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb15376-0114-46b7-9840-3bc16ce5e2f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a bitsandbytes configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27bd92b-65ba-4b59-8428-cf83ca310a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    return bnb_config\n",
    "\n",
    "# SOURCE https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "def create_peft_config(modules):\n",
    "    \"\"\"\n",
    "    Create Parameter-Efficient Fine-Tuning config for your model\n",
    "    :param modules: Names of the modules to apply Lora to\n",
    "    \"\"\"\n",
    "    config = LoraConfig(\n",
    "        r=8,  # dimension of the updated matrices\n",
    "        lora_alpha=16,  # parameter for scaling\n",
    "        target_modules=modules,\n",
    "        lora_dropout=0.1,  # dropout probability for layers\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    print(\"Lora target_modules\", str(modules))\n",
    "\n",
    "    return config\n",
    "\n",
    "def print_trainable_parameters(model, use_4bit=False):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    if use_4bit:\n",
    "        trainable_params /= 2\n",
    "    print(\n",
    "        f\"all params: {all_param:,d} || trainable params: {trainable_params:,d} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7f95fe-ec6e-4d5a-97df-3f57c93fcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, bnb_config):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"cuda:0\", # dispatch efficiently the model on the available ressources  \n",
    "        load_in_8bit=True,\n",
    "        trust_remote_code=True,\n",
    "        #max_memory=f'{int(torch.cuda.mem_get_info()[0]/1024**3)-2}GB',\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "\n",
    "    # Needed for LLaMA tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "340d5ff0-b6af-4998-94fc-51b6b0a9f887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a9637071a4461fb69a97cf0aeb8988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4f2301-a0f2-4b6c-be72-20031add62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-13b-chat-hf\" \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cff6c67-3cd6-4082-8494-f2331f8751bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d528d0b894148a68a27f4898a10223a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the .\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu/disk.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:664: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model from HF with user's token and with bitsandbytes config\n",
    "\n",
    "bnb_config = create_bnb_config()\n",
    "model = load_model(model_name, bnb_config)\n",
    "tokenizer = load_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3524ee7-e11a-4442-9276-77b8cb8c25c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found max lenth: 4096\n",
      "Preprocessing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Preprocess dataset\n",
    "\n",
    "max_length = get_max_length(model)\n",
    "\n",
    "dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b07cd5-37b1-42b0-a20f-edf8bce43b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d70081d4-ab3c-4ec2-98bd-71335910b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tokenizer, dataset, output_dir):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    # 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # Get lora module names\n",
    "    modules = find_all_linear_names(model)\n",
    "\n",
    "    # Create PEFT config for these modules and wrap the model to PEFT\n",
    "    peft_config = create_peft_config(modules)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    # Print information about the percentage of trainable parameters\n",
    "    print_trainable_parameters(model)\n",
    "    \n",
    "    # Training parameters\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        args=TrainingArguments(\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=4,\n",
    "            num_train_epochs = 100,\n",
    "            max_steps=100,\n",
    "            learning_rate=2e-4,\n",
    "            fp16=True,\n",
    "            logging_steps=5,\n",
    "            output_dir=\"outputs\",\n",
    "            optim=\"paged_adamw_8bit\",\n",
    "        ),\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False  # re-enable for inference to speed up predictions for similar inputs\n",
    "    \n",
    "    ### SOURCE https://github.com/artidoro/qlora/blob/main/qlora.py\n",
    "    # Verifying the datatypes before training\n",
    "    \n",
    "    dtypes = {}\n",
    "    for _, p in model.named_parameters():\n",
    "        dtype = p.dtype\n",
    "        if dtype not in dtypes: dtypes[dtype] = 0\n",
    "        dtypes[dtype] += p.numel()\n",
    "    total = 0\n",
    "    for k, v in dtypes.items(): total+= v\n",
    "    for k, v in dtypes.items():\n",
    "        print(k, v, v/total)\n",
    "     \n",
    "    do_train = True\n",
    "    \n",
    "    # Launch training\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    if do_train:\n",
    "        train_result = trainer.train()\n",
    "        metrics = train_result.metrics\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "        print(metrics)    \n",
    "    \n",
    "    ###\n",
    "    \n",
    "    # Saving model\n",
    "    print(\"Saving last checkpoint of the model...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    \n",
    "    # Free memory for merging weights\n",
    "    del model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc69099a-80d7-429f-92ab-959889d5ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora target_modules ['o_proj', 'k_proj', 'down_proj', 'up_proj', 'q_proj', 'gate_proj', 'v_proj']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:XRT configuration not detected. Defaulting to preview PJRT runtime. To silence this warning and continue using PJRT, explicitly set PJRT_DEVICE to a supported device or configure XRT. To disable default device selection, set PJRT_SELECT_DEFAULT_DEVICE=0\n",
      "WARNING:root:For more information about the status of PJRT, see https://github.com/pytorch/xla/blob/master/docs/pjrt.md\n",
      "WARNING:root:Defaulting to PJRT_DEVICE=CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all params: 6,703,272,960 || trainable params: 31,293,440 || trainable%: 0.46683821749069876\n",
      "torch.float32 359388160 0.05361383344293949\n",
      "torch.uint8 6343884800 0.9463861665570605\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 1:00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.977500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.06\n",
      "  total_flos               = 28123773GF\n",
      "  train_loss               =     1.1201\n",
      "  train_runtime            = 1:00:34.43\n",
      "  train_samples_per_second =       0.22\n",
      "  train_steps_per_second   =      0.028\n",
      "{'train_runtime': 3634.4315, 'train_samples_per_second': 0.22, 'train_steps_per_second': 0.028, 'total_flos': 3.019767229710336e+16, 'train_loss': 1.1200517749786376, 'epoch': 0.06}\n",
      "Saving last checkpoint of the model...\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"results/kisai_llama2_13b_chat/final_checkpoint\"\n",
    "train(model, tokenizer, dataset, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bb78a-8dda-4ccd-8414-246552515b57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38438d91-a152-47d8-a174-98cb3e925c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/kisai_llama2/final_checkpoint'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daf24ec7-3e0c-4d28-8ae6-5f9f490d877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/keep-it-simple-ai/text_simplification/llama-2-qlora'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2296c-70f3-49e0-902f-38d2b69d7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep-it-simple-ai/text_simplification/llama-2-qlora/results/kisai_llama2_13b_chat/final_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa9980-dd26-4d22-85b6-7bf44ba3a456",
   "metadata": {},
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e64dd-8d19-4250-95c5-86715b5c95d6",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ccb977-4cf3-45cb-87f4-214744f3a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"results/kisai_llama2_13b_chat/final_checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc7e375-d33f-4eb3-a257-7cf0ecd5cac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeed31dd2a648bc98821551a445db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the .\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu/disk.\n"
     ]
    }
   ],
   "source": [
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map = \"auto\",\n",
    ")\n",
    "\n",
    "# Merge LoRA and base model\n",
    "# merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc85aa97-5993-4ff9-88bb-b6392b7855f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:664: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516804d3-80ce-4574-99ba-717cc1cc9dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1640f3e35e274923b75a45ef1a6654b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/125M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/egehanyorulmaz/kisai-llama-2-13b-chat/commit/104d76ea8b75dd3865e35a34d8c6713a559a2be2', commit_message='Upload model', commit_description='', oid='104d76ea8b75dd3865e35a34d8c6713a559a2be2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"egehanyorulmaz/kisai-llama-2-13b-chat\", token=\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b785135-bfb1-4878-b992-3d5ff8ccf602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f0b5ae9b490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d20da5a-04aa-482f-83b1-571d78ad1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436a6d99-1a58-46f5-b019-aee0e7568cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 5120,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 13824,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 40,\n",
      "  \"num_key_value_heads\": 40,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.0.dev0\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = True\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "367ca9e4-d9de-45ff-baf9-84a2e793924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_improvement(instruction, context=None):\n",
    "    if context: \n",
    "        prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: \\n{context}\\n\\n### Response: \\n\"\n",
    "    else:\n",
    "        prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: \\n{instruction}\\n\\n### Response: \\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids = inputs.input_ids,\n",
    "            attention_mask = inputs.attention_mask,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=250,\n",
    "            use_cache = True,\n",
    "        )\n",
    "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bd14dd0-bb1c-4029-acc9-c2836a69170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 37s ± 180 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "\n",
    "answer = make_improvement_experimental(instruction=\"Summarize the following context. Your answer must be in English. End the response with the phrase 'End of response.'\",  \n",
    "                        context=\"Today Sunday 3 September (20.00) Serbia-Turkey-Euro 2023 final of women’s volleyball. TO Brussels (Belgium) the continental title is up for grabs and it will be decided who will succeed Italy in the golden register. It promises to be a particularly balanced and compelling, exciting and intense challenge, open to any result. It will be a cross between Italian coaches, given that coach Daniele Santarelli sits on the Anatolian bench, capable of beating Italy in the tie-break, and Giovanni Guidetti is on the Balkan bench.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33a14c-4580-4845-aefc-10063a698b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf3e35a8-0da2-44f2-8586-ff60ed788c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_improvement_experimental(instruction, context=None):\n",
    "    if context: \n",
    "        prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: \\n{context}\\n\\n### Response: \\n\"\n",
    "    else:\n",
    "        prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: \\n{instruction}\\n\\n### Response: \\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    with torch.inference_mode():\n",
    "        outputs = merged_model.generate(\n",
    "            input_ids = inputs.input_ids,\n",
    "            attention_mask = inputs.attention_mask,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=250,\n",
    "            use_cache = True,\n",
    "        )\n",
    "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fe98c-7920-4c5d-b3d1-9b9b07a5a4a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Trying no_grad and .eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f903176d-92db-4a6f-aa3d-b756e7bb615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, context=None):\n",
    "    if context: \n",
    "        prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: \\n{context}\\n\\n### Response: \\n\"\n",
    "    else:\n",
    "        prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: \\n{instruction}\\n\\n### Response: \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "902803ab-d335-45a0-9c75-f7f454d4843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_improvement_experimental(instruction, context=None):\n",
    "    prompt = generate_prompt(instruction, context)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    merged_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = merged_model.generate(\n",
    "            input_ids = inputs.input_ids,\n",
    "            attention_mask = inputs.attention_mask,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=250,\n",
    "            use_cache = True,\n",
    "        )\n",
    "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce2997fb-155c-48d2-a392-b217cb11ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 37s ± 446 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "\n",
    "answer = make_improvement_experimental(instruction=\"Summarize the following context. Your answer must be in English. End the response with the phrase 'End of response.'\",  \n",
    "                        context=\"Today Sunday 3 September (20.00) Serbia-Turkey-Euro 2023 final of women’s volleyball. TO Brussels (Belgium) the continental title is up for grabs and it will be decided who will succeed Italy in the golden register. It promises to be a particularly balanced and compelling, exciting and intense challenge, open to any result. It will be a cross between Italian coaches, given that coach Daniele Santarelli sits on the Anatolian bench, capable of beating Italy in the tie-break, and Giovanni Guidetti is on the Balkan bench.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f99503-8423-4aec-b3a8-da844f63f10c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "535b197a-8066-4842-b5fe-846e571bc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, context=None):\n",
    "    if context: \n",
    "        prompt = f\"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction: \\n{instruction}\\n\\n### Input: \\n{context}\\n\\n### Response: \\n\"\n",
    "    else:\n",
    "        prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction: \\n{instruction}\\n\\n### Response: \\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee2409f8-797b-4a0c-b8d6-8b755841fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=\"Summarize the following context. Your answer must be in English. End the response with the phrase 'End of response.'\"  \n",
    "context=\"Today Sunday 3 September (20.00) Serbia-Turkey-Euro 2023 final of women’s volleyball. TO Brussels (Belgium) the continental title is up for grabs and it will be decided who will succeed Italy in the golden register. It promises to be a particularly balanced and compelling, exciting and intense challenge, open to any result. It will be a cross between Italian coaches, given that coach Daniele Santarelli sits on the Anatolian bench, capable of beating Italy in the tie-break, and Giovanni Guidetti is on the Balkan bench.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef151b4-9995-48b7-95b8-c3b8729469fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_improvement_experimental(instruction, context=None):\n",
    "    prompt = generate_prompt(instruction, context)\n",
    "    \n",
    "    inputs = tokenizer(text=prompt, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda\")\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids = inputs.input_ids,\n",
    "            attention_mask = inputs.attention_mask,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=250,\n",
    "            use_cache = True,\n",
    "        )\n",
    "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37357435-4428-404a-91eb-4d5ad97b08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3 s ± 6.3 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "\n",
    "answer = make_improvement_experimental(instruction=instruction, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ccc92-7532-4850-8dea-3dc811a10909",
   "metadata": {},
   "source": [
    "### Inference speed comparison\n",
    "\n",
    "41.7 seconds with merged model \\\n",
    "29.3 seconds when the quantized model is saved, and reloaded as llama 2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bca92-c849-49f4-80b9-35ef598dfb18",
   "metadata": {},
   "source": [
    "### Inferencing on Text Simplification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79003e3b-4069-405c-8cac-ecd9a17d5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"gs://XXX/Text_Simplification/finetuned_llama2_responses_chat_responses.csv\"\n",
    "data = pd.read_csv(PATH)\n",
    "data[\"model_13b_chat_response\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4626f896-e2bb-4230-bef8-2619eb801731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_level</th>\n",
       "      <th>target_level</th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>oob_model_response</th>\n",
       "      <th>model_13b_chat_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>\\nDonald Trump is interested in buying Greenl...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>\\nEveryone knows that children don't like eat...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Archaeologists have found a big cemetery under...</td>\n",
       "      <td>Archaeologists found a big cemetery under the ...</td>\n",
       "      <td>\\nThe text has been simplified from CEFR Leve...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>\\nAfter seven or eight years, the young apes ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>New research says bald men should not worry ab...</td>\n",
       "      <td>Research says bald men should not worry or get...</td>\n",
       "      <td>\\nThe bald men were rated as more attractive,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_level  target_level  \\\n",
       "0             2             1   \n",
       "1             2             1   \n",
       "2             2             1   \n",
       "3             2             1   \n",
       "4             2             1   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  Simplify the following text from intermediate ...   \n",
       "1  Simplify the following text from intermediate ...   \n",
       "2  Simplify the following text from intermediate ...   \n",
       "3  Simplify the following text from intermediate ...   \n",
       "4  Simplify the following text from intermediate ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "2  Archaeologists have found a big cemetery under...   \n",
       "3  Baby orangutans in Indonesia are going to scho...   \n",
       "4  New research says bald men should not worry ab...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows children don't like eating gree...   \n",
       "2  Archaeologists found a big cemetery under the ...   \n",
       "3  Baby orangutans in Indonesia are going to scho...   \n",
       "4  Research says bald men should not worry or get...   \n",
       "\n",
       "                                  oob_model_response model_13b_chat_response  \n",
       "0   \\nDonald Trump is interested in buying Greenl...                          \n",
       "1   \\nEveryone knows that children don't like eat...                          \n",
       "2   \\nThe text has been simplified from CEFR Leve...                          \n",
       "3   \\nAfter seven or eight years, the young apes ...                          \n",
       "4   \\nThe bald men were rated as more attractive,...                          "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53824b33-3371-4b17-a0a3-768e0b4ccfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald Trump is interested in buying Greenland. He said it would be like buying property and was, \"a large real estate deal\". He added: \"They\\'ve got a lot of valuable minerals.\" Mr Trump said: \"Denmark owns it....We protect Denmark....So the concept came up and I said, \\'Certainly I\\'d be [interested].\\' He said buying Greenland was not his top priority at the moment. He said: \"It\\'s not number one on the burner.\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4948533a-8a72-45e6-961e-b5bd2452d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald Trump is interested in buying Greenland. He said it would be, \"a large real estate deal\". He added: \"They\\'ve got a lot of valuable minerals.\" Mr Trump said: \"Certainly I\\'d be [interested].\\' He said buying Greenland was not his top priority. He said: \"It\\'s not number one on the burner.\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc787dc2-3bca-4c86-9e6a-eee9ace7e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_inference(instruction, context=None):\n",
    "    prompt = generate_prompt(instruction, context)\n",
    "    \n",
    "    inputs = tokenizer(text=prompt, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda\")\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids = inputs.input_ids,\n",
    "            attention_mask = inputs.attention_mask,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=250,\n",
    "            use_cache = False,\n",
    "        )\n",
    "    decoded_response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    return decoded_response\n",
    "\n",
    "def generate_prompt(instruction, context):\n",
    "    \"\"\"\n",
    "    Format various fields of the sample ('instruction', 'context', 'response')\n",
    "    Then concatenate them using two newline characters \n",
    "    :param sample: Sample dictionary\n",
    "    \"\"\"\n",
    "    SYSTEM_PROMPT = f\"\"\"<s>[INST] <<SYS>> \\n\n",
    "    You are a helpful, respectful and honest assistant. Always simplify the text to the asked target language level from the source language level, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.<</SYS>>\\n\"\"\"\n",
    "    INSTRUCTION = f\"{instruction}:\\n {context} [/INST] \\n\\n\"\n",
    "    formatted_prompt = SYSTEM_PROMPT + INSTRUCTION\n",
    "    return formatted_prompt\n",
    "\n",
    "\n",
    "def map_cefr_to_text(language_level):\n",
    "    if int(language_level) == 3:\n",
    "        return \"advanced\"\n",
    "    elif int(language_level) == 2:\n",
    "        return \"intermediate\"\n",
    "    elif int(language_level) == 1:\n",
    "        return \"beginner\"\n",
    "    else:\n",
    "        raise Exception(\"Unrecognized language level\")\n",
    "        \n",
    "        \n",
    "def generate_instruction_column(source_cefr, target_cefr):\n",
    "    source_level_text = map_cefr_to_text(source_cefr)\n",
    "    target_level_text = map_cefr_to_text(target_cefr)\n",
    "    return f\"Simplify the following text from {source_level_text} language level to {target_level_text} language level\"\n",
    "\n",
    "\n",
    "def extract_levels(text):\n",
    "    # Regular expression to find 'CEFR Level X' where X is a digit\n",
    "    pattern = re.compile(r'CEFR Level (\\d)')\n",
    "    levels = pattern.findall(text)\n",
    "    \n",
    "    # If both levels are found, return them\n",
    "    if len(levels) == 2:\n",
    "        source_level, target_level = levels\n",
    "        return source_level, target_level\n",
    "    else:\n",
    "        print('Could not extract both levels from the text.')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5093d09-73dd-44ca-85e0-835f0a4d4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['source_level', 'target_level']] = data['instruction'].apply(lambda x: pd.Series(extract_levels(x)))\n",
    "data[\"instruction\"] = data.apply(lambda row: generate_instruction_column(row[\"source_level\"], row[\"target_level\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fc002c1-da04-4651-b21d-eb4bdb8dbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>model_response</th>\n",
       "      <th>oob_model_response</th>\n",
       "      <th>model_v2_response</th>\n",
       "      <th>model_13b_chat_response</th>\n",
       "      <th>source_level</th>\n",
       "      <th>target_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>\\nDonald Trump is interested in buying Greenl...</td>\n",
       "      <td>\\nDonald Trump is interested in buying Greenl...</td>\n",
       "      <td>&lt;s&gt; Below is an instruction that describes a t...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>\\nChildren don't like eating greens. Parents ...</td>\n",
       "      <td>\\nEveryone knows that children don't like eat...</td>\n",
       "      <td>&lt;s&gt; Below is an instruction that describes a t...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Archaeologists have found a big cemetery under...</td>\n",
       "      <td>Archaeologists found a big cemetery under the ...</td>\n",
       "      <td>\\nArchaeologists have found a big cemetery un...</td>\n",
       "      <td>\\nThe text has been simplified from CEFR Leve...</td>\n",
       "      <td>&lt;s&gt; Below is an instruction that describes a t...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>\\nBaby orangutans in Indonesia are going to s...</td>\n",
       "      <td>\\nAfter seven or eight years, the young apes ...</td>\n",
       "      <td>&lt;s&gt; Below is an instruction that describes a t...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>New research says bald men should not worry ab...</td>\n",
       "      <td>Research says bald men should not worry or get...</td>\n",
       "      <td>\\nBald men should not worry about their looks...</td>\n",
       "      <td>\\nThe bald men were rated as more attractive,...</td>\n",
       "      <td>&lt;s&gt; Below is an instruction that describes a t...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Simplify the following text from advanced lang...</td>\n",
       "      <td>The president of the Philippines, Rodrigo Dute...</td>\n",
       "      <td>The Philippines president has angered people. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>Simplify the following text from advanced lang...</td>\n",
       "      <td>If you are afraid of insects, this might be di...</td>\n",
       "      <td>If you dislike insects, reading this might be ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>Simplify the following text from advanced lang...</td>\n",
       "      <td>People around the world are trying to get hold...</td>\n",
       "      <td>People are trying to buy clothes worn in the v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>Simplify the following text from advanced lang...</td>\n",
       "      <td>People around the world are living longer. Thi...</td>\n",
       "      <td>We are living longer, so more people have ment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>Simplify the following text from advanced lang...</td>\n",
       "      <td>Nature is full of secrets. There are still man...</td>\n",
       "      <td>Nature still has many secrets. We uncovered on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruction  \\\n",
       "0     Simplify the following text from intermediate ...   \n",
       "1     Simplify the following text from intermediate ...   \n",
       "2     Simplify the following text from intermediate ...   \n",
       "3     Simplify the following text from intermediate ...   \n",
       "4     Simplify the following text from intermediate ...   \n",
       "...                                                 ...   \n",
       "2395  Simplify the following text from advanced lang...   \n",
       "2396  Simplify the following text from advanced lang...   \n",
       "2397  Simplify the following text from advanced lang...   \n",
       "2398  Simplify the following text from advanced lang...   \n",
       "2399  Simplify the following text from advanced lang...   \n",
       "\n",
       "                                                context  \\\n",
       "0     Donald Trump is interested in buying Greenland...   \n",
       "1     Everyone knows that children don't like eating...   \n",
       "2     Archaeologists have found a big cemetery under...   \n",
       "3     Baby orangutans in Indonesia are going to scho...   \n",
       "4     New research says bald men should not worry ab...   \n",
       "...                                                 ...   \n",
       "2395  The president of the Philippines, Rodrigo Dute...   \n",
       "2396  If you are afraid of insects, this might be di...   \n",
       "2397  People around the world are trying to get hold...   \n",
       "2398  People around the world are living longer. Thi...   \n",
       "2399  Nature is full of secrets. There are still man...   \n",
       "\n",
       "                                               response  \\\n",
       "0     Donald Trump is interested in buying Greenland...   \n",
       "1     Everyone knows children don't like eating gree...   \n",
       "2     Archaeologists found a big cemetery under the ...   \n",
       "3     Baby orangutans in Indonesia are going to scho...   \n",
       "4     Research says bald men should not worry or get...   \n",
       "...                                                 ...   \n",
       "2395  The Philippines president has angered people. ...   \n",
       "2396  If you dislike insects, reading this might be ...   \n",
       "2397  People are trying to buy clothes worn in the v...   \n",
       "2398  We are living longer, so more people have ment...   \n",
       "2399  Nature still has many secrets. We uncovered on...   \n",
       "\n",
       "                                         model_response  \\\n",
       "0      \\nDonald Trump is interested in buying Greenl...   \n",
       "1      \\nChildren don't like eating greens. Parents ...   \n",
       "2      \\nArchaeologists have found a big cemetery un...   \n",
       "3      \\nBaby orangutans in Indonesia are going to s...   \n",
       "4      \\nBald men should not worry about their looks...   \n",
       "...                                                 ...   \n",
       "2395                                                NaN   \n",
       "2396                                                NaN   \n",
       "2397                                                NaN   \n",
       "2398                                                NaN   \n",
       "2399                                                NaN   \n",
       "\n",
       "                                     oob_model_response  \\\n",
       "0      \\nDonald Trump is interested in buying Greenl...   \n",
       "1      \\nEveryone knows that children don't like eat...   \n",
       "2      \\nThe text has been simplified from CEFR Leve...   \n",
       "3      \\nAfter seven or eight years, the young apes ...   \n",
       "4      \\nThe bald men were rated as more attractive,...   \n",
       "...                                                 ...   \n",
       "2395                                                NaN   \n",
       "2396                                                NaN   \n",
       "2397                                                NaN   \n",
       "2398                                                NaN   \n",
       "2399                                                NaN   \n",
       "\n",
       "                                      model_v2_response  \\\n",
       "0     <s> Below is an instruction that describes a t...   \n",
       "1     <s> Below is an instruction that describes a t...   \n",
       "2     <s> Below is an instruction that describes a t...   \n",
       "3     <s> Below is an instruction that describes a t...   \n",
       "4     <s> Below is an instruction that describes a t...   \n",
       "...                                                 ...   \n",
       "2395                                                NaN   \n",
       "2396                                                NaN   \n",
       "2397                                                NaN   \n",
       "2398                                                NaN   \n",
       "2399                                                NaN   \n",
       "\n",
       "     model_13b_chat_response source_level target_level  \n",
       "0                                       2            1  \n",
       "1                                       2            1  \n",
       "2                                       2            1  \n",
       "3                                       2            1  \n",
       "4                                       2            1  \n",
       "...                      ...          ...          ...  \n",
       "2395                                    3            2  \n",
       "2396                                    3            2  \n",
       "2397                                    3            2  \n",
       "2398                                    3            2  \n",
       "2399                                    3            2  \n",
       "\n",
       "[2400 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1c402e9-bfe8-4900-a1a1-a3ed00bb9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['source_level', 'target_level', 'instruction', 'context', 'response', 'oob_model_response', 'model_13b_chat_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fce85c3a-ad72-401a-84f3-7db71860db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_level</th>\n",
       "      <th>target_level</th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>oob_model_response</th>\n",
       "      <th>model_13b_chat_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>Donald Trump is interested in buying Greenland...</td>\n",
       "      <td>\\nDonald Trump is interested in buying Greenl...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Everyone knows that children don't like eating...</td>\n",
       "      <td>Everyone knows children don't like eating gree...</td>\n",
       "      <td>\\nEveryone knows that children don't like eat...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Archaeologists have found a big cemetery under...</td>\n",
       "      <td>Archaeologists found a big cemetery under the ...</td>\n",
       "      <td>\\nThe text has been simplified from CEFR Leve...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>Baby orangutans in Indonesia are going to scho...</td>\n",
       "      <td>\\nAfter seven or eight years, the young apes ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Simplify the following text from intermediate ...</td>\n",
       "      <td>New research says bald men should not worry ab...</td>\n",
       "      <td>Research says bald men should not worry or get...</td>\n",
       "      <td>\\nThe bald men were rated as more attractive,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_level target_level  \\\n",
       "0            2            1   \n",
       "1            2            1   \n",
       "2            2            1   \n",
       "3            2            1   \n",
       "4            2            1   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  Simplify the following text from intermediate ...   \n",
       "1  Simplify the following text from intermediate ...   \n",
       "2  Simplify the following text from intermediate ...   \n",
       "3  Simplify the following text from intermediate ...   \n",
       "4  Simplify the following text from intermediate ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows that children don't like eating...   \n",
       "2  Archaeologists have found a big cemetery under...   \n",
       "3  Baby orangutans in Indonesia are going to scho...   \n",
       "4  New research says bald men should not worry ab...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Donald Trump is interested in buying Greenland...   \n",
       "1  Everyone knows children don't like eating gree...   \n",
       "2  Archaeologists found a big cemetery under the ...   \n",
       "3  Baby orangutans in Indonesia are going to scho...   \n",
       "4  Research says bald men should not worry or get...   \n",
       "\n",
       "                                  oob_model_response model_13b_chat_response  \n",
       "0   \\nDonald Trump is interested in buying Greenl...                          \n",
       "1   \\nEveryone knows that children don't like eat...                          \n",
       "2   \\nThe text has been simplified from CEFR Leve...                          \n",
       "3   \\nAfter seven or eight years, the young apes ...                          \n",
       "4   \\nThe bald men were rated as more attractive,...                          "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d420da6-bc98-4b77-a6d0-d8b2782e676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>> \n",
      "\n",
      "    You are a helpful, respectful and honest assistant. Always simplify the text to the asked target language level from the source language level, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.<</SYS>>\n",
      "Simplify the following text from intermediate language level to beginner language level:\n",
      " Donald Trump is interested in buying Greenland. He said it would be like buying property and was, \"a large real estate deal\". He added: \"They've got a lot of valuable minerals.\" Mr Trump said: \"Denmark owns it....We protect Denmark....So the concept came up and I said, 'Certainly I'd be [interested].' He said buying Greenland was not his top priority at the moment. He said: \"It's not number one on the burner.\" [/INST] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(data.iloc[0]['instruction'], data.iloc[0]['context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60b3b0a2-65d6-4039-86d8-c0a6102d5c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://XXX/Text_Simplification/finetuned_llama2_responses_chat_responses.csv'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a16bf3-bb86-4fae-bf1a-e1e598a2f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing index  0\n",
      "Finished processing index 0 in 364.532160576 seconds.\n",
      "Saving for batch 0\n",
      "Finishes saving the batch 0 in 0.2831193409997468 seconds\n",
      "Currently processing index  1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    print(\"Currently processing index \", idx)\n",
    "    start = time.perf_counter()\n",
    "    answer = make_inference(instruction=row[\"instruction\"],  \n",
    "                            context=row[\"context\"])\n",
    "    data.at[idx, 'model_13b_chat_response'] = answer\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f\"Finished processing index {idx} in {end-start} seconds.\")\n",
    "    \n",
    "    if idx % 20 == 0:\n",
    "        print(f\"Saving for batch {idx//20}\")\n",
    "        start = time.perf_counter()\n",
    "        data.to_csv(PATH, index=False)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"Finishes saving the batch {idx//20} in {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47bfcf75-7396-467e-b1c7-d410dccbc64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch._dynamo.eval_frame.OptimizedModule"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb6d3e-7950-4bea-9e13-410822ddaf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
